{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>CASE_STATUS</th>\n",
       "      <th>FULL_TIME_POSITION</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_HA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_LA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_MA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_VHA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_VLA</th>\n",
       "      <th>JOB_ACCEPTANCE_HA</th>\n",
       "      <th>JOB_ACCEPTANCE_LA</th>\n",
       "      <th>...</th>\n",
       "      <th>ILLINOIS</th>\n",
       "      <th>MASSACHUSETTS</th>\n",
       "      <th>PENNSYLVANIA</th>\n",
       "      <th>FLORIDA</th>\n",
       "      <th>GEORGIA</th>\n",
       "      <th>WASHINGTON</th>\n",
       "      <th>VIRGINIA</th>\n",
       "      <th>MICHIGAN</th>\n",
       "      <th>NORTH CAROLINA</th>\n",
       "      <th>OHIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  CASE_STATUS  FULL_TIME_POSITION  EMPLOYER_ACCEPTANCE_HA  \\\n",
       "0          18          1.0                   1                       0   \n",
       "1          19          1.0                   1                       0   \n",
       "2          22          1.0                   1                       0   \n",
       "3          23          1.0                   1                       0   \n",
       "4          25          1.0                   1                       0   \n",
       "\n",
       "   EMPLOYER_ACCEPTANCE_LA  EMPLOYER_ACCEPTANCE_MA  EMPLOYER_ACCEPTANCE_VHA  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "\n",
       "   EMPLOYER_ACCEPTANCE_VLA  JOB_ACCEPTANCE_HA  JOB_ACCEPTANCE_LA  ...  \\\n",
       "0                        0                  0                  0  ...   \n",
       "1                        0                  0                  0  ...   \n",
       "2                        0                  0                  0  ...   \n",
       "3                        0                  0                  0  ...   \n",
       "4                        0                  0                  0  ...   \n",
       "\n",
       "   ILLINOIS  MASSACHUSETTS  PENNSYLVANIA  FLORIDA  GEORGIA  WASHINGTON  \\\n",
       "0         0              0             0        0        0           0   \n",
       "1         0              0             0        0        0           0   \n",
       "2         0              0             0        0        0           0   \n",
       "3         0              0             0        0        0           0   \n",
       "4         0              0             0        0        0           0   \n",
       "\n",
       "   VIRGINIA  MICHIGAN  NORTH CAROLINA  OHIO  \n",
       "0         0         0               0     0  \n",
       "1         1         0               0     0  \n",
       "2         0         0               0     0  \n",
       "3         0         0               0     0  \n",
       "4         0         0               0     0  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('visawise.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(['CASE_STATUS','Unnamed: 0'], axis=1) # Independent variables\n",
    "y = df['CASE_STATUS'] # Dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['FULL_TIME_POSITION', 'EMPLOYER_ACCEPTANCE_HA',\n",
       "       'EMPLOYER_ACCEPTANCE_LA', 'EMPLOYER_ACCEPTANCE_MA',\n",
       "       'EMPLOYER_ACCEPTANCE_VHA', 'EMPLOYER_ACCEPTANCE_VLA',\n",
       "       'JOB_ACCEPTANCE_HA', 'JOB_ACCEPTANCE_LA', 'JOB_ACCEPTANCE_MA',\n",
       "       'JOB_ACCEPTANCE_VHA', 'JOB_ACCEPTANCE_VLA', 'SOC_ACCEPTANCE_HA',\n",
       "       'SOC_ACCEPTANCE_LA', 'SOC_ACCEPTANCE_MA', 'SOC_ACCEPTANCE_VHA',\n",
       "       'SOC_ACCEPTANCE_VLA', 'YEAR_2012.0', 'YEAR_2013.0', 'YEAR_2014.0',\n",
       "       'YEAR_2015.0', 'YEAR_2016.0', 'WAGE_CATEGORY_LOW',\n",
       "       'WAGE_CATEGORY_MEDIUM', 'WAGE_CATEGORY_VERY HIGH',\n",
       "       'WAGE_CATEGORY_VERY LOW', 'JOB_Artist', 'JOB_Audit', 'JOB_Database',\n",
       "       'JOB_Education', 'JOB_Engineer', 'JOB_Estate', 'JOB_Finance', 'JOB_It',\n",
       "       'JOB_Manager', 'JOB_Medical', 'JOB_Pr', 'JOB_Scm', 'CALIFORNIA',\n",
       "       'TEXAS', 'NEW YORK', 'NEW JERSEY', 'ILLINOIS', 'MASSACHUSETTS',\n",
       "       'PENNSYLVANIA', 'FLORIDA', 'GEORGIA', 'WASHINGTON', 'VIRGINIA',\n",
       "       'MICHIGAN', 'NORTH CAROLINA', 'OHIO'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.columns.shape)\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4317: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)\n",
    "\n",
    "X_train.fillna(0, inplace=True)\n",
    "X_test.fillna(0, inplace=True)\n",
    "y_train.fillna(0, inplace=True)\n",
    "y_test.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FULL_TIME_POSITION</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_HA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_LA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_MA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_VHA</th>\n",
       "      <th>EMPLOYER_ACCEPTANCE_VLA</th>\n",
       "      <th>JOB_ACCEPTANCE_HA</th>\n",
       "      <th>JOB_ACCEPTANCE_LA</th>\n",
       "      <th>JOB_ACCEPTANCE_MA</th>\n",
       "      <th>JOB_ACCEPTANCE_VHA</th>\n",
       "      <th>...</th>\n",
       "      <th>ILLINOIS</th>\n",
       "      <th>MASSACHUSETTS</th>\n",
       "      <th>PENNSYLVANIA</th>\n",
       "      <th>FLORIDA</th>\n",
       "      <th>GEORGIA</th>\n",
       "      <th>WASHINGTON</th>\n",
       "      <th>VIRGINIA</th>\n",
       "      <th>MICHIGAN</th>\n",
       "      <th>NORTH CAROLINA</th>\n",
       "      <th>OHIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118611</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303000</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051437</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410149</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1712576</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>836489</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491263</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568076</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491755</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128037</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2155216 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         FULL_TIME_POSITION  EMPLOYER_ACCEPTANCE_HA  EMPLOYER_ACCEPTANCE_LA  \\\n",
       "118611                    1                       0                       0   \n",
       "1303000                   1                       0                       0   \n",
       "1051437                   1                       0                       0   \n",
       "410149                    0                       0                       0   \n",
       "1712576                   1                       0                       0   \n",
       "...                     ...                     ...                     ...   \n",
       "836489                    1                       0                       0   \n",
       "491263                    1                       0                       0   \n",
       "2568076                   1                       0                       0   \n",
       "491755                    1                       0                       0   \n",
       "128037                    0                       0                       0   \n",
       "\n",
       "         EMPLOYER_ACCEPTANCE_MA  EMPLOYER_ACCEPTANCE_VHA  \\\n",
       "118611                        0                        0   \n",
       "1303000                       0                        0   \n",
       "1051437                       0                        0   \n",
       "410149                        0                        1   \n",
       "1712576                       0                        0   \n",
       "...                         ...                      ...   \n",
       "836489                        0                        1   \n",
       "491263                        0                        0   \n",
       "2568076                       0                        0   \n",
       "491755                        0                        0   \n",
       "128037                        0                        0   \n",
       "\n",
       "         EMPLOYER_ACCEPTANCE_VLA  JOB_ACCEPTANCE_HA  JOB_ACCEPTANCE_LA  \\\n",
       "118611                         0                  0                  0   \n",
       "1303000                        0                  0                  0   \n",
       "1051437                        0                  0                  0   \n",
       "410149                         0                  0                  0   \n",
       "1712576                        0                  0                  0   \n",
       "...                          ...                ...                ...   \n",
       "836489                         0                  0                  0   \n",
       "491263                         0                  0                  0   \n",
       "2568076                        0                  0                  0   \n",
       "491755                         0                  0                  0   \n",
       "128037                         0                  0                  0   \n",
       "\n",
       "         JOB_ACCEPTANCE_MA  JOB_ACCEPTANCE_VHA  ...  ILLINOIS  MASSACHUSETTS  \\\n",
       "118611                   0                   0  ...         0              0   \n",
       "1303000                  0                   1  ...         0              0   \n",
       "1051437                  0                   0  ...         0              0   \n",
       "410149                   0                   0  ...         1              0   \n",
       "1712576                  0                   0  ...         0              0   \n",
       "...                    ...                 ...  ...       ...            ...   \n",
       "836489                   0                   0  ...         0              0   \n",
       "491263                   0                   0  ...         0              0   \n",
       "2568076                  0                   1  ...         0              0   \n",
       "491755                   0                   0  ...         0              0   \n",
       "128037                   0                   1  ...         0              0   \n",
       "\n",
       "         PENNSYLVANIA  FLORIDA  GEORGIA  WASHINGTON  VIRGINIA  MICHIGAN  \\\n",
       "118611              0        0        0           0         0         0   \n",
       "1303000             0        0        0           0         0         0   \n",
       "1051437             0        0        0           0         0         0   \n",
       "410149              0        0        0           0         0         0   \n",
       "1712576             0        0        0           0         0         0   \n",
       "...               ...      ...      ...         ...       ...       ...   \n",
       "836489              0        0        0           0         0         0   \n",
       "491263              0        0        0           0         0         0   \n",
       "2568076             0        0        0           0         0         0   \n",
       "491755              0        0        0           0         0         0   \n",
       "128037              0        0        0           0         0         0   \n",
       "\n",
       "         NORTH CAROLINA  OHIO  \n",
       "118611                0     0  \n",
       "1303000               0     0  \n",
       "1051437               0     0  \n",
       "410149                0     0  \n",
       "1712576               0     0  \n",
       "...                 ...   ...  \n",
       "836489                0     0  \n",
       "491263                0     0  \n",
       "2568076               0     0  \n",
       "491755                0     0  \n",
       "128037                0     0  \n",
       "\n",
       "[2155216 rows x 51 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   227  18685]\n",
      " [    32 519860]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.01      0.02     18912\n",
      "         1.0       0.97      1.00      0.98    519892\n",
      "\n",
      "    accuracy                           0.97    538804\n",
      "   macro avg       0.92      0.51      0.50    538804\n",
      "weighted avg       0.96      0.97      0.95    538804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(20,20,20,20,20), max_iter=1000)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred_mlp = mlp.predict(X_test)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_mlp)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999384487547414\n",
      "0.9823163778288174\n"
     ]
    }
   ],
   "source": [
    "print(metrics.recall_score(y_test, y_pred_mlp))\n",
    "print(metrics.f1_score(y_test, y_pred_mlp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] 51\n",
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "x = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "print(x, len(x))\n",
    "prediction = mlp.predict([x])\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# open a file, where you ant to store the data\n",
    "file = open('nueral_netwoks.pkl', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(mlp, file)\n",
    "\n",
    "file.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Logistic Regression Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1285464    1.0\n",
      "2646597    1.0\n",
      "1279586    1.0\n",
      "1426548    1.0\n",
      "76436      1.0\n",
      "410927     1.0\n",
      "843402     1.0\n",
      "508583     1.0\n",
      "1627361    1.0\n",
      "2048489    1.0\n",
      "Name: CASE_STATUS, dtype: float64\n",
      "pred [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "[[    27  18885]\n",
      " [     8 519884]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.77      0.00      0.00     18912\n",
      "         1.0       0.96      1.00      0.98    519892\n",
      "\n",
      "    accuracy                           0.96    538804\n",
      "   macro avg       0.87      0.50      0.49    538804\n",
      "weighted avg       0.96      0.96      0.95    538804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "print(\"test\", y_test[:10])\n",
    "print(\"pred\", y_pred[:10])\n",
    "print()\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Applying Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1285464    1.0\n",
      "2646597    1.0\n",
      "1279586    1.0\n",
      "1426548    1.0\n",
      "76436      1.0\n",
      "410927     1.0\n",
      "843402     1.0\n",
      "508583     1.0\n",
      "1627361    1.0\n",
      "2048489    1.0\n",
      "Name: CASE_STATUS, dtype: float64\n",
      "pred [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "\n",
      "0.9650912019955309\n",
      "[[   270  18642]\n",
      " [   167 519725]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.01      0.03     18912\n",
      "         1.0       0.97      1.00      0.98    519892\n",
      "\n",
      "    accuracy                           0.97    538804\n",
      "   macro avg       0.79      0.51      0.51    538804\n",
      "weighted avg       0.95      0.97      0.95    538804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "dtree = tree.DecisionTreeClassifier()\n",
    "dtree = dtree.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = dtree.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"test\", y_test[:10])\n",
    "print(\"pred\", y_pred[:10])\n",
    "print()\n",
    "\n",
    "print(dtree.score(X_test,y_test))\n",
    "print(metrics.confusion_matrix(y_test,y_pred_dt))\n",
    "print(metrics.classification_report(y_test, y_pred_dt))\n",
    "#print(metrics.precision_score(y_test,y_pred))   # Parameter \"average\" is requred if not a binary model\n",
    "#print(metrics.recall_score(y_test,y_pred))      # Parameter \"average\" is requred if not a binary model\n",
    "#print(metrics.f1_score(y_test,y_pred))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "# Applying Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1285464    1.0\n",
      "2646597    1.0\n",
      "1279586    1.0\n",
      "1426548    1.0\n",
      "76436      1.0\n",
      "410927     1.0\n",
      "843402     1.0\n",
      "508583     1.0\n",
      "1627361    1.0\n",
      "2048489    1.0\n",
      "Name: CASE_STATUS, dtype: float64\n",
      "pred [[0.00258843 0.99741157]\n",
      " [0.0426505  0.9573495 ]\n",
      " [0.01609128 0.98390872]\n",
      " [0.02264496 0.97735504]\n",
      " [0.00348062 0.99651938]\n",
      " [0.00348062 0.99651938]\n",
      " [0.01915826 0.98084174]\n",
      " [0.01654143 0.98345857]\n",
      " [0.05611203 0.94388797]\n",
      " [0.07162147 0.92837853]]\n",
      "[[   244  18668]\n",
      " [   100 519792]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.71      0.01      0.03     18912\n",
      "         1.0       0.97      1.00      0.98    519892\n",
      "\n",
      "    accuracy                           0.97    538804\n",
      "   macro avg       0.84      0.51      0.50    538804\n",
      "weighted avg       0.96      0.97      0.95    538804\n",
      "\n",
      "0.9653307580878803\n",
      "0.9998076523585668\n",
      "0.9822667694680032\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rd =  RandomForestClassifier(n_estimators = 75 , random_state = 50)\n",
    "# rd.fit(X_train,y_train)\n",
    "\n",
    "# y_pred_rfs = rd.predict_proba(X_test)\n",
    "\n",
    "print(\"test\", y_test[:10])\n",
    "print(\"pred\", y_pred_rfs[:10])\n",
    "\n",
    "print(metrics.confusion_matrix(y_test,pred))\n",
    "print(metrics.classification_report(y_test, pred))\n",
    "print(metrics.precision_score(y_test,pred))   # Parameter \"average\" is requred if not a binary model\n",
    "print(metrics.recall_score(y_test,pred))\n",
    "print(metrics.f1_score(y_test, pred))# Parameter \"average\" is requred if not a binary model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(538804, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_rfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=0\n",
    "pred = np.zeros((538804,1))\n",
    "for i in y_pred_rfs:\n",
    "    pred[j] = np.argmax(i, axis=0)\n",
    "    j +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.] [   344 538460]\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(pred, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "#   Applying Gaussian Naive bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1501  17411]\n",
      " [ 13025 506867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.10      0.08      0.09     18912\n",
      "         1.0       0.97      0.97      0.97    519892\n",
      "\n",
      "    accuracy                           0.94    538804\n",
      "   macro avg       0.54      0.53      0.53    538804\n",
      "weighted avg       0.94      0.94      0.94    538804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gaus_clf = GaussianNB()\n",
    "gaus_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_glb = gaus_clf.predict(X_test)\n",
    "confusion = metrics.confusion_matrix(y_test, y_pred_glb)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_pred_glb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br>\n",
    "# Applying naive bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1285464    1.0\n",
      "2646597    1.0\n",
      "1279586    1.0\n",
      "1426548    1.0\n",
      "76436      1.0\n",
      "          ... \n",
      "951187     1.0\n",
      "1902794    1.0\n",
      "2525449    1.0\n",
      "1697574    1.0\n",
      "2349247    1.0\n",
      "Name: CASE_STATUS, Length: 538804, dtype: float64\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "0.9435119264148002\n",
      "[[  1501  17411]\n",
      " [ 13025 506867]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.10      0.08      0.09     18912\n",
      "         1.0       0.97      0.97      0.97    519892\n",
      "\n",
      "    accuracy                           0.94    538804\n",
      "   macro avg       0.54      0.53      0.53    538804\n",
      "weighted avg       0.94      0.94      0.94    538804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pipe  = Pipeline([(\"mn\",MinMaxScaler()),(\"nb\",GaussianNB())])\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# do this again\n",
    "y_prednb = pipe.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_prednb)\n",
    "print(accuracy_score(y_test,y_prednb))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_prednb)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_prednb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn_clf.fit(X_train,y_train)\n",
    "knn_clf.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "y_predknn = pipe.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_predknn)\n",
    "print(accuracy_score(y_test,y_predknn))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_predknn)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_predknn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradint Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gb_clf = GradientBoostingClassifier()\n",
    "gb_clf.fit(X_train,y_train)\n",
    "gb_clf.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "y_predgb = pipe.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_predgb)\n",
    "print(accuracy_score(y_test,y_pred))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_predgb)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_predgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Gradiant Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_clf_ = GradientBoostingClassifier(n_estimators = 40)\n",
    "gb_clf_.fit(X_train,y_train)\n",
    "gb_clf_.score(X_test,y_test)\n",
    "\n",
    "\n",
    "\n",
    "y_predgbc = pipe.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_predgbc)\n",
    "print(accuracy_score(y_test,y_predgbc))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_predgbc)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_predgbc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "sv_clf = SVC(probability=True,kernel='linear')\n",
    "sv_clf.fit(X_train,y_train)\n",
    "sv_clf.fit(X_test)\n",
    "\n",
    "\n",
    "\n",
    "y_predsvm = pipe.predict(X_test)\n",
    "print(y_test)\n",
    "print(y_predsvm)\n",
    "print(accuracy_score(y_test,y_predsvm))\n",
    "\n",
    "confusion = metrics.confusion_matrix(y_test, y_predsvm)\n",
    "print(confusion)\n",
    "print(metrics.classification_report(y_test, y_predsvm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
